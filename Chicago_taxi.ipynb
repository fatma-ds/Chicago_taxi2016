{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatma-ds/Chicago_taxi2016/blob/main/Chicago_taxi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKAwzMbCmZH-"
      },
      "source": [
        "# Chicago Taxi Rides_2016"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGI97oh05mPb",
        "outputId": "806b504c-f44b-4d5e-9d42-b5fb1a7e6993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kDgM6Ya5puD",
        "outputId": "af0e0dba-d70c-47ac-c922-81acaf477900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.8/dist-packages (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Hgg2J4g7guu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import findspark \n",
        "from pyspark.sql import SparkSession \n",
        "\n",
        "\n",
        "#Load Module\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VrHpHRa7nxL",
        "outputId": "0ebe17f0-1ba0-49ca-873f-cc00bf098119"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------------------+-------------------+------------+----------+-------------------+--------------------+---------------------+----------------------+-----+----+-----+------+----------+------------+-------+---------------+----------------+----------------+-----------------+\n",
            "|taxi_id|trip_start_timestamp| trip_end_timestamp|trip_seconds|trip_miles|pickup_census_tract|dropoff_census_tract|pickup_community_area|dropoff_community_area| fare|tips|tolls|extras|trip_total|payment_type|company|pickup_latitude|pickup_longitude|dropoff_latitude|dropoff_longitude|\n",
            "+-------+--------------------+-------------------+------------+----------+-------------------+--------------------+---------------------+----------------------+-----+----+-----+------+----------+------------+-------+---------------+----------------+----------------+-----------------+\n",
            "|     85| 2016-01-13 06:15:00|2016-01-13 06:15:00|         180|       0.4|               null|                null|                   24|                    24|  4.5| 0.0|  0.0|   0.0|       4.5|        Cash|    107|            199|             510|             199|              510|\n",
            "|   2776| 2016-01-22 09:30:00|2016-01-22 09:45:00|         240|       0.7|               null|                null|                 null|                  null| 4.45|4.45|  0.0|   0.0|       8.9| Credit Card|   null|           null|            null|            null|             null|\n",
            "|   3168| 2016-01-31 21:30:00|2016-01-31 21:30:00|           0|       0.0|               null|                null|                 null|                  null|42.75| 5.0|  0.0|   0.0|     47.75| Credit Card|    119|           null|            null|            null|             null|\n",
            "|   4237| 2016-01-23 17:30:00|2016-01-23 17:30:00|         480|       1.1|               null|                null|                    6|                     6|  7.0| 0.0|  0.0|   0.0|       7.0|        Cash|   null|            686|             500|             686|              500|\n",
            "|   5710| 2016-01-14 05:45:00|2016-01-14 06:00:00|         480|      2.71|               null|                null|                   32|                  null|10.25| 0.0|  0.0|   0.0|     10.25|        Cash|   null|            385|             478|            null|             null|\n",
            "+-------+--------------------+-------------------+------------+----------+-------------------+--------------------+---------------------+----------------------+-----+----+-----+------+----------+------------+-------+---------------+----------------+----------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "findspark.init()\n",
        "\n",
        "spark = SparkSession\\\n",
        "    .builder\\\n",
        "    .appName(\"chicago_taxi_trips\")\\\n",
        "    .getOrCreate()\n",
        "#Creat Spark Session\n",
        "spark=SparkSession.builder.master('local').appName('Regression taxi trips').getOrCreate()\n",
        "\n",
        "#Load dataset\n",
        "data=spark.read.csv('/content/chicago_taxi_trips_2016_*.csv',inferSchema=True, header=True)\n",
        "data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6Lq1wM_7xFB",
        "outputId": "12a8b347-305a-4d82-f06e-c1aaa0fc1837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame Rows count : 19866157\n"
          ]
        }
      ],
      "source": [
        "#checking the numbers of rows\n",
        "# we have about 20 M records \n",
        "rows = data.count()\n",
        "print(f\"DataFrame Rows count : {rows}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKj6Dboflo4Z"
      },
      "source": [
        "## drop missing values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tQRhn7a90nN",
        "outputId": "da7e638d-c838-4647-ce79-96e8628f8407"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7564042"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Dropped \"pickup_census_tract\" column because it is all null\n",
        "#dropping \"pickup_census_tract\" column improved model performance\n",
        "df = data.drop(\"pickup_census_tract\")\n",
        "df = df.na.drop()\n",
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6btfYm4_8O8",
        "outputId": "f8848247-7f9b-479b-fb28-9b024b3e50d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------------+----------+\n",
            "| fare|trip_seconds|trip_miles|\n",
            "+-----+------------+----------+\n",
            "|  5.0|         180|       0.0|\n",
            "|  7.0|         480|       1.3|\n",
            "| 7.25|         420|       0.0|\n",
            "| 6.25|         420|       0.0|\n",
            "|10.75|         720|       0.0|\n",
            "+-----+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#first select features and label\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "df1=df.select(\"fare\",\"trip_seconds\",\"trip_miles\")\n",
        "df1.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meZ2CVjZApLu",
        "outputId": "bea941da-e1be-4cb2-f06a-a0a31b98fcac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- fare: double (nullable = true)\n",
            " |-- trip_seconds: integer (nullable = true)\n",
            " |-- trip_miles: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df1.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsjIKeUTAsud",
        "outputId": "bc42303c-7c4f-45e5-f28d-d4ffbb369d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+------------+----------+\n",
            "|fare|trip_seconds|trip_miles|\n",
            "+----+------------+----------+\n",
            "|   5|         180|         0|\n",
            "|   7|         480|         1|\n",
            "|   7|         420|         0|\n",
            "|   6|         420|         0|\n",
            "|  10|         720|         0|\n",
            "+----+------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# converting fare and trip_miles to integer\n",
        "df1 = df1.withColumn(\"fare\", df1[\"fare\"].cast(IntegerType()))\n",
        "df1 = df1.withColumn(\"trip_miles\", df1[\"trip_miles\"].cast(IntegerType()))\n",
        "df1.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJccZBJ-Aw0k",
        "outputId": "5b1bc47b-a21b-4414-bf48-2f295e9b89df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- fare: integer (nullable = true)\n",
            " |-- trip_seconds: integer (nullable = true)\n",
            " |-- trip_miles: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df1.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg7sVYylA0z5",
        "outputId": "e5022c85-c55a-479c-941e-41ffbcb5771d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[fare: int, trip_seconds: int, trip_miles: int]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checking null values and drop them \n",
        "df1 = df1.na.drop()\n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "cX9DXL4EA4x8",
        "outputId": "edd36b1a-a0bd-41e7-d118-cf06d3a386cd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-440196e1-d663-420d-ae1c-5349b1ff8fad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>summary</th>\n",
              "      <td>count</td>\n",
              "      <td>mean</td>\n",
              "      <td>stddev</td>\n",
              "      <td>min</td>\n",
              "      <td>max</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fare</th>\n",
              "      <td>7564042</td>\n",
              "      <td>11.585207221218496</td>\n",
              "      <td>11.980659225126931</td>\n",
              "      <td>0</td>\n",
              "      <td>4444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trip_seconds</th>\n",
              "      <td>7564042</td>\n",
              "      <td>739.3545963917176</td>\n",
              "      <td>715.5603996367231</td>\n",
              "      <td>0</td>\n",
              "      <td>79140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trip_miles</th>\n",
              "      <td>7564042</td>\n",
              "      <td>1.8509856238238762</td>\n",
              "      <td>4.946990067093426</td>\n",
              "      <td>0</td>\n",
              "      <td>995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-440196e1-d663-420d-ae1c-5349b1ff8fad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-440196e1-d663-420d-ae1c-5349b1ff8fad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-440196e1-d663-420d-ae1c-5349b1ff8fad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                    0                   1                   2    3      4\n",
              "summary         count                mean              stddev  min    max\n",
              "fare          7564042  11.585207221218496  11.980659225126931    0   4444\n",
              "trip_seconds  7564042   739.3545963917176   715.5603996367231    0  79140\n",
              "trip_miles    7564042  1.8509856238238762   4.946990067093426    0    995"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.describe().toPandas().transpose()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8dw5XyLA9Pk",
        "outputId": "9191561c-19bf-428c-e732-bbdd7affb6f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----+\n",
            "|   features|label|\n",
            "+-----------+-----+\n",
            "|[180.0,0.0]|    5|\n",
            "|[480.0,1.0]|    7|\n",
            "|[420.0,0.0]|    7|\n",
            "|[420.0,0.0]|    6|\n",
            "|[720.0,0.0]|   10|\n",
            "+-----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "#Assembler combine all features/predictors into a vector\n",
        "assembler=VectorAssembler(inputCols=(\"trip_seconds\",\"trip_miles\"),\n",
        "                         outputCol=('features'))\n",
        "# we transfor the data \n",
        "newdata=assembler.transform(df1).select(col('features'),(col('fare').cast('Int').alias('label')))\n",
        "newdata.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw2lNfFDBRfW",
        "outputId": "72730764-7b37-4e8e-fc30-3766c81e54f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train:\n",
            " 6050601 \n",
            "test:\n",
            " 1513441\n"
          ]
        }
      ],
      "source": [
        "#Split dataset into 80/20\n",
        "\n",
        "splitdata=newdata.randomSplit([0.8,0.2])\n",
        "train=splitdata[0]\n",
        "test=splitdata[1]\n",
        "\n",
        "print('train:\\n', train.count(), '\\ntest:\\n',test.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjEVkJ2Mmzzr"
      },
      "source": [
        "## Build a linear regression with elastic net Regularizers to  forecast fare using trip_seconds, trip_miles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UODbtW38BVfy",
        "outputId": "979c93d2-833d-41ef-849f-25ea089cf310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Trained\n"
          ]
        }
      ],
      "source": [
        "#now we will build the linear regression model\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "# Crearte a linear regression model object\n",
        "lrmodel = LinearRegression(\n",
        "    labelCol=\"label\",featuresCol=\"features\", maxIter=10, regParam=0.1, elasticNetParam=0.8)\n",
        "#Train our model on the training dataset\n",
        "model = lrmodel.fit(train)\n",
        "print (\"Model Trained\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDuKzdcpDbe6",
        "outputId": "3056f342-b263-4795-b064-8f9a7f71acb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-----+------------------+\n",
            "| features|label|        prediction|\n",
            "+---------+-----+------------------+\n",
            "|(2,[],[])|    0|1.7249579238275843|\n",
            "|(2,[],[])|    0|1.7249579238275843|\n",
            "|(2,[],[])|    0|1.7249579238275843|\n",
            "|(2,[],[])|    0|1.7249579238275843|\n",
            "|(2,[],[])|    0|1.7249579238275843|\n",
            "+---------+-----+------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Root Mean Square Error (RMSE): 5.25491120474526\n",
            "R2 : 0.7978889644913532\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "# forecast the Test dataset using transform method\n",
        "predictions1=model.transform(test)\n",
        "predictions1.show(5)\n",
        "# setup the metric to use, such as root meaned squared error, which is very popular for regression project\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "evaluator2 = RegressionEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "\n",
        "rmse = evaluator.evaluate(predictions1)\n",
        "r2 = evaluator2.evaluate(predictions1)\n",
        "print (\"Root Mean Square Error (RMSE):\", rmse)\n",
        "print (\"R2 :\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhWMqbGRnPIM"
      },
      "source": [
        "## Build a simple tree model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkr7pLQ5EamK"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.ml import Pipeline\n",
        "#import the libary for tree regression\n",
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "from pyspark.ml.feature import VectorIndexer\n",
        "\n",
        "\n",
        "# Automatically identify categorical features, and index them.\n",
        "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
        "featureIndexer =\\\n",
        "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(newdata)\n",
        "\n",
        "\n",
        "dt = DecisionTreeRegressor(featuresCol=\"indexedFeatures\")\n",
        "\n",
        "# Chain indexer and tree in a Pipeline, then the data was process by the feature Indexer first,\n",
        "# then the processed data will be passed to the tree model\n",
        "pipeline = Pipeline(stages=[featureIndexer, dt])\n",
        "\n",
        "# Train model, this also runs the indexer.\n",
        "model2 = pipeline.fit(train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pJiML2lElE8",
        "outputId": "31466fd9-03b3-4bd1-f7a1-e4c829ac39d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+-----+---------+\n",
            "|       prediction|label| features|\n",
            "+-----------------+-----+---------+\n",
            "|4.211091781238388|    0|(2,[],[])|\n",
            "|4.211091781238388|    0|(2,[],[])|\n",
            "|4.211091781238388|    0|(2,[],[])|\n",
            "|4.211091781238388|    0|(2,[],[])|\n",
            "|4.211091781238388|    0|(2,[],[])|\n",
            "+-----------------+-----+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Root Mean Square Error (RMSE): 3.775949971166071\n",
            "R2 : 0.8956453690666406\n",
            "DecisionTreeRegressionModel: uid=DecisionTreeRegressor_22b1f98c5546, depth=5, numNodes=63, numFeatures=2\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test dataset\n",
        "predictions = model2.transform(test)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "\n",
        "# Evaluate our model on the test dataset\n",
        "# Select (prediction, true label) and compute test error using root mean squared error for regression\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "evaluator2 = RegressionEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "# evaluate the model performance on the predicted dataset\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "r2 = evaluator2.evaluate(predictions)\n",
        "print (\"Root Mean Square Error (RMSE):\", rmse)\n",
        "print (\"R2 :\", r2)\n",
        "\n",
        "treeModel = model2.stages[1]\n",
        "# summary only\n",
        "print(treeModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1pVKfQ1nYlk"
      },
      "source": [
        "##  Build a random forest model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AjxEil3WHaYI"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "\n",
        "# Train a RandomForest model.\n",
        "featureIndexer =\\\n",
        "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(newdata)\n",
        "\n",
        "rf = RandomForestRegressor(featuresCol=\"indexedFeatures\")\n",
        "\n",
        "# Chain indexer and forest in a Pipeline\n",
        "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
        "\n",
        "# Train model.  This also runs the indexer.\n",
        "model3 = pipeline.fit(train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yHo_0Nu9HF5l",
        "outputId": "11fdad06-53c5-41a4-8aff-257d158786c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+-----+---------+\n",
            "|       prediction|label| features|\n",
            "+-----------------+-----+---------+\n",
            "|5.447869659183243|    0|(2,[],[])|\n",
            "|5.447869659183243|    0|(2,[],[])|\n",
            "|5.447869659183243|    0|(2,[],[])|\n",
            "|5.447869659183243|    0|(2,[],[])|\n",
            "|5.447869659183243|    0|(2,[],[])|\n",
            "+-----------------+-----+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Root Mean Square Error (RMSE): 3.7364716003591947\n",
            "R2 : 0.8978160622195315\n",
            "RandomForestRegressionModel: uid=RandomForestRegressor_d29bf69184b9, numTrees=20, numFeatures=2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Make predictions on the test dataset\n",
        "predictions = model3.transform(test)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "# evaluate the model performance on the test dataset using root mean squared error\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "evaluator2 = RegressionEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "# evaluate the model performance on the predicted dataset\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "r2 = evaluator2.evaluate(predictions)\n",
        "print (\"Root Mean Square Error (RMSE):\", rmse)\n",
        "print (\"R2 :\", r2)\n",
        "\n",
        "\n",
        "rfModel = model3.stages[1]\n",
        "print(rfModel)  # summary only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P40EHOxHniBW"
      },
      "source": [
        "## Build a Gradient-Boosted Tree model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jEhXinZ0LKDu"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import GBTRegressor\n",
        "# Train a GBT model.\n",
        "featureIndexer =\\\n",
        "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(newdata)\n",
        "\n",
        "gbt = GBTRegressor(featuresCol=\"indexedFeatures\", maxIter=10)\n",
        "\n",
        "# Chain indexer and GBT in a Pipeline\n",
        "pipeline = Pipeline(stages=[featureIndexer, gbt])\n",
        "\n",
        "# Train model.  This also runs the indexer first, then pass the processed data to the gbt model.\n",
        "model4 = pipeline.fit(train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBTXHxI0LPS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "961b2b8e-44bd-4330-dc74-71768ef945b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+---------+\n",
            "|       prediction|label| features|\n",
            "+-----------------+-----+---------+\n",
            "|4.189686399593084|    0|(2,[],[])|\n",
            "|4.189686399593084|    0|(2,[],[])|\n",
            "|4.189686399593084|    0|(2,[],[])|\n",
            "|4.189686399593084|    0|(2,[],[])|\n",
            "|4.189686399593084|    0|(2,[],[])|\n",
            "+-----------------+-----+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Root Mean Square Error (RMSE): 3.5639460686984554\n",
            "R2 : 0.9070345640302035\n",
            "GBTRegressionModel: uid=GBTRegressor_e3f032210b20, numTrees=10, numFeatures=2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Make predictions on the test dataset\n",
        "predictions = model4.transform(test)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test error using rmse for regression\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "evaluator2 = RegressionEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "# evaluate the model performance on the predicted dataset\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "r2 = evaluator2.evaluate(predictions)\n",
        "print (\"Root Mean Square Error (RMSE):\", rmse)\n",
        "print (\"R2 :\", r2)\n",
        "\n",
        "\n",
        "# our pipeline has two steps/stages stages=[featureIndexer, gbt]\n",
        "# stages[0]= featureIndexer; stages[1] = gbt\n",
        "gbtModel = model4.stages[1]\n",
        "print(gbtModel)  # summary only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xP5s2DlpHi8"
      },
      "source": [
        " ### perform hyper parameter tuning on the  Gradient-Boosted Tree model since it gave the lowest RMSE score and highest R2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmR7AcTBRzTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71073244-8ddd-434f-a16c-8591e08aa772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 6.422820798040719\n"
          ]
        }
      ],
      "source": [
        "# we first need to build a parameter grid using ParamGridBuilder\n",
        "# then select the optimal parameter using CrossValidator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# Train the Gradient-boosted model.\n",
        "gb = GBTRegressor(featuresCol=\"features\" ,labelCol=\"label\")\n",
        "gbparamGrid = (ParamGridBuilder()\n",
        "             .addGrid(gb.maxDepth, [2])\n",
        "             .addGrid(gb.maxBins, [5])\n",
        "             .addGrid(gb.maxIter, [10])\n",
        "             .build())\n",
        "\n",
        "\n",
        "gbevaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"rmse\")\n",
        "\n",
        "#set the estimator to be the best model above, and paragrid, the CrossValidator, the number of fold\n",
        "gbcv = CrossValidator(estimator = gb, estimatorParamMaps= gbparamGrid,evaluator = gbevaluator,numFolds = 5)\n",
        "\n",
        "\n",
        "\n",
        "# fit on the training dataset\n",
        "gbcvModel = gbcv.fit(train)\n",
        "\n",
        "\n",
        "#evaluate on the test dataset\n",
        "gbpredictions = gbcvModel.transform(test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('RMSE:', gbevaluator.evaluate(gbpredictions))\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPA74Z9rDIl8u3tFX3umvNj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}